{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a45f4b-d39c-46ec-9ae6-fac82dc60e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 KB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /work/festusedward-n/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting numpy>=1.22.4\n",
      "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.6 pandas-2.3.0 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29bee61e-72ce-45b1-b42c-e5388cd988fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2378557/1950638804.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mouse_data = pd.read_csv(\"logger_mouseactionlog_modified.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keystroke Data Head:\n",
      "   id  key action  rhythm  dwell_time  flight_time  up_down_time  \\\n",
      "0 NaN  NaN    NaN     NaN         NaN          NaN           NaN   \n",
      "1 NaN  NaN    NaN     NaN         NaN          NaN           NaN   \n",
      "2 NaN  NaN    NaN     NaN         NaN          NaN           NaN   \n",
      "3 NaN  NaN    NaN     NaN         NaN          NaN           NaN   \n",
      "4 NaN  NaN    NaN     NaN         NaN          NaN           NaN   \n",
      "\n",
      "   session_duration  user_id timestamp  \n",
      "0               NaN      NaN       NaN  \n",
      "1               NaN      NaN       NaN  \n",
      "2               NaN      NaN       NaN  \n",
      "3               NaN      NaN       NaN  \n",
      "4               NaN      NaN       NaN  \n",
      "Mouse Data Head:\n",
      "   id action coordinates button delta  distance  speed  user_id timestamp\n",
      "0 NaN    NaN         NaN    NaN   NaN       NaN    NaN      NaN       NaN\n",
      "1 NaN    NaN         NaN    NaN   NaN       NaN    NaN      NaN       NaN\n",
      "2 NaN    NaN         NaN    NaN   NaN       NaN    NaN      NaN       NaN\n",
      "3 NaN    NaN         NaN    NaN   NaN       NaN    NaN      NaN       NaN\n",
      "4 NaN    NaN         NaN    NaN   NaN       NaN    NaN      NaN       NaN\n",
      "Keystroke Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23063 entries, 0 to 23062\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                19996 non-null  float64\n",
      " 1   key               19705 non-null  object \n",
      " 2   action            19996 non-null  object \n",
      " 3   rhythm            19996 non-null  float64\n",
      " 4   dwell_time        19705 non-null  float64\n",
      " 5   flight_time       19705 non-null  float64\n",
      " 6   up_down_time      19705 non-null  float64\n",
      " 7   session_duration  19579 non-null  float64\n",
      " 8   user_id           19659 non-null  float64\n",
      " 9   timestamp         19996 non-null  object \n",
      "dtypes: float64(7), object(3)\n",
      "memory usage: 1.8+ MB\n",
      "None\n",
      "Mouse Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 316358 entries, 0 to 316357\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   id           252397 non-null  float64\n",
      " 1   action       252397 non-null  object \n",
      " 2   coordinates  252397 non-null  object \n",
      " 3   button       3228 non-null    object \n",
      " 4   delta        249902 non-null  object \n",
      " 5   distance     252343 non-null  float64\n",
      " 6   speed        252343 non-null  float64\n",
      " 7   user_id      252325 non-null  float64\n",
      " 8   timestamp    252397 non-null  object \n",
      "dtypes: float64(4), object(5)\n",
      "memory usage: 21.7+ MB\n",
      "None\n",
      "Keystroke Data Description:\n",
      "                 id        rhythm    dwell_time   flight_time  up_down_time  \\\n",
      "count  19996.000000  19996.000000  19705.000000  19705.000000  19705.000000   \n",
      "mean   13065.480746      0.352955      0.354278      4.845072      2.544296   \n",
      "std     5772.525036      7.159179      7.169444    264.831756    171.229414   \n",
      "min     3067.000000    -75.194930      0.000000     -2.041683     -2.041683   \n",
      "25%     8066.750000      0.060000      0.061000      0.000000      0.000000   \n",
      "50%    13065.500000      0.083000      0.083000      0.000000      0.000000   \n",
      "75%    18064.250000      0.119000      0.117000      0.180000      0.221000   \n",
      "max    23063.000000    447.000000    447.000000  20046.000000  19986.000000   \n",
      "\n",
      "       session_duration       user_id  \n",
      "count      19579.000000  19659.000000  \n",
      "mean          13.830218     50.118928  \n",
      "std           49.841288     22.658151  \n",
      "min            0.000000      1.000000  \n",
      "25%            3.239000     39.000000  \n",
      "50%            4.531000     54.000000  \n",
      "75%            9.169000     67.000000  \n",
      "max         1184.299000     85.000000  \n",
      "Mouse Data Description:\n",
      "                  id       distance          speed        user_id\n",
      "count  252397.000000  252343.000000  252343.000000  252325.000000\n",
      "mean   190160.999770      12.704394     629.512314      52.270322\n",
      "std     72860.882682      35.375617    1233.469142      19.709480\n",
      "min     63962.000000       0.000000       0.000000       1.000000\n",
      "25%    127062.000000       1.414214      66.666664      39.000000\n",
      "50%    190161.000000       4.000000     230.769230      58.000000\n",
      "75%    253260.000000      12.000000     677.596400      66.000000\n",
      "max    316359.000000    1511.016200   84090.730000      85.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the keystroke and mouse dynamics data\n",
    "keystroke_data = pd.read_csv(\"logger_keystrokelog_modified.csv\")\n",
    "mouse_data = pd.read_csv(\"logger_mouseactionlog_modified.csv\")\n",
    "\n",
    "# Check the first few rows to understand the structure\n",
    "print(\"Keystroke Data Head:\")\n",
    "print(keystroke_data.head())  # Display the first few rows\n",
    "\n",
    "print(\"Mouse Data Head:\")\n",
    "print(mouse_data.head())  # Display the first few rows\n",
    "\n",
    "# Check for null values and data types\n",
    "print(\"Keystroke Data Info:\")\n",
    "print(keystroke_data.info())  # Summary of the data: columns, types, and null values\n",
    "\n",
    "print(\"Mouse Data Info:\")\n",
    "print(mouse_data.info())  # Summary of the data: columns, types, and null values\n",
    "\n",
    "# Get basic statistics for numerical columns to understand distributions\n",
    "print(\"Keystroke Data Description:\")\n",
    "print(keystroke_data.describe())\n",
    "\n",
    "print(\"Mouse Data Description:\")\n",
    "print(mouse_data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5dfada-d7e9-4390-ae84-145c482b9350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keystroke Data Missing Values:\n",
      "id                  3067\n",
      "key                 3358\n",
      "action              3067\n",
      "rhythm              3067\n",
      "dwell_time          3358\n",
      "flight_time         3358\n",
      "up_down_time        3358\n",
      "session_duration    3484\n",
      "user_id             3404\n",
      "timestamp           3067\n",
      "dtype: int64\n",
      "Mouse Data Missing Values:\n",
      "id              63961\n",
      "action          63961\n",
      "coordinates     63961\n",
      "button         313130\n",
      "delta           66456\n",
      "distance        64015\n",
      "speed           64015\n",
      "user_id         64033\n",
      "timestamp       63961\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "keystroke_missing = keystroke_data.isnull().sum()\n",
    "mouse_missing = mouse_data.isnull().sum()\n",
    "\n",
    "print(\"Keystroke Data Missing Values:\")\n",
    "print(keystroke_missing)\n",
    "\n",
    "print(\"Mouse Data Missing Values:\")\n",
    "print(mouse_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5323e083-332d-4a4e-8f85-e70cddf09fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2378557/3274398638.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mouse_data = pd.read_csv(\"logger_mouseactionlog_modified.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keystroke Data Missing Information:\n",
      "Total Rows: 23063\n",
      "Total Columns: 10\n",
      "Rows with Missing Values: 3484\n",
      "Rows with No Missing Values: 19579\n",
      "\n",
      "Mouse Data Missing Information:\n",
      "Total Rows: 316358\n",
      "Total Columns: 9\n",
      "Rows with Missing Values: 313445\n",
      "Rows with No Missing Values: 2913\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "keystroke_data = pd.read_csv(\"logger_keystrokelog_modified.csv\")\n",
    "mouse_data = pd.read_csv(\"logger_mouseactionlog_modified.csv\")\n",
    "\n",
    "# Function to check missing data in a dataframe\n",
    "def check_missing_data(df):\n",
    "    # Count rows with missing values (any NaN in the row)\n",
    "    missing_rows = df.isnull().any(axis=1).sum()\n",
    "\n",
    "    # Count rows with no missing values (complete rows)\n",
    "    complete_rows = df.notnull().all(axis=1).sum()\n",
    "\n",
    "    # Count total number of rows\n",
    "    total_rows = len(df)\n",
    "\n",
    "    # Count total number of columns\n",
    "    total_columns = len(df.columns)\n",
    "\n",
    "    print(f\"Total Rows: {total_rows}\")\n",
    "    print(f\"Total Columns: {total_columns}\")\n",
    "    print(f\"Rows with Missing Values: {missing_rows}\")\n",
    "    print(f\"Rows with No Missing Values: {complete_rows}\")\n",
    "\n",
    "    return missing_rows, complete_rows, total_rows, total_columns\n",
    "\n",
    "# Check missing data for keystroke and mouse data\n",
    "print(\"Keystroke Data Missing Information:\")\n",
    "keystroke_missing, keystroke_complete, keystroke_total_rows, keystroke_total_columns = check_missing_data(keystroke_data)\n",
    "\n",
    "print(\"\\nMouse Data Missing Information:\")\n",
    "mouse_missing, mouse_complete, mouse_total_rows, mouse_total_columns = check_missing_data(mouse_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "955ffbe1-f2b5-4ba7-bba2-3c3ecad3588a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with Missing Data: 313445\n",
      "Rows with No Missing Data: 2913\n",
      "Total Rows: 316358\n"
     ]
    }
   ],
   "source": [
    "# Count the number of missing rows in the mouse data\n",
    "mouse_missing_rows = mouse_data.isnull().any(axis=1).sum()\n",
    "mouse_non_missing_rows = mouse_data.notnull().all(axis=1).sum()\n",
    "\n",
    "print(f\"Rows with Missing Data: {mouse_missing_rows}\")\n",
    "print(f\"Rows with No Missing Data: {mouse_non_missing_rows}\")\n",
    "print(f\"Total Rows: {len(mouse_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09d0a9e2-5458-41c4-8f5a-ed60a158c5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 316358\n",
      "Rows with Missing Data: 313445\n",
      "Rows with No Missing Data: 2913\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataset is already loaded\n",
    "# mouse_data = pd.read_csv(\"mouse_data.csv\")\n",
    "\n",
    "# Count rows with missing values (at least one NaN in the row)\n",
    "missing_rows = mouse_data.isnull().any(axis=1).sum()\n",
    "\n",
    "# Count rows with no missing values (completely filled rows)\n",
    "non_missing_rows = mouse_data.notnull().all(axis=1).sum()\n",
    "\n",
    "# Count total rows in the dataset\n",
    "total_rows = len(mouse_data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total Rows: {total_rows}\")\n",
    "print(f\"Rows with Missing Data: {missing_rows}\")\n",
    "print(f\"Rows with No Missing Data: {non_missing_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c8b2591-4af5-4574-8b19-1d9df635d74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2378557/1954353286.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mouse_data = pd.read_csv(\"mouse_modified.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: (316358, 9)\n",
      "New dataset size: (259358, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "mouse_data = pd.read_csv(\"mouse_modified.csv\")\n",
    "\n",
    "# Delete the first 57,000 rows\n",
    "mouse_data_trimmed = mouse_data.iloc[57000:].reset_index(drop=True)\n",
    "\n",
    "# Verify the shape of the new dataset\n",
    "print(f\"Original dataset size: {mouse_data.shape}\")\n",
    "print(f\"New dataset size: {mouse_data_trimmed.shape}\")\n",
    "\n",
    "# Optionally, save the trimmed dataset to a new CSV file\n",
    "mouse_data_trimmed.to_csv(\"mouse_modified_trimmed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a83de291-af05-4707-a8eb-0ea46be2b3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (259358, 9)\n",
      "\n",
      "First 5 Rows of the Dataset:\n",
      "   id action coordinates button delta  distance  speed  user_id timestamp\n",
      "0 NaN    NaN         NaN    NaN   NaN       NaN    NaN      NaN       NaN\n",
      "1 NaN    NaN         NaN    NaN   NaN       NaN    NaN      NaN       NaN\n",
      "2 NaN    NaN         NaN    NaN   NaN       NaN    NaN      NaN       NaN\n",
      "3 NaN    NaN         NaN    NaN   NaN       NaN    NaN      NaN       NaN\n",
      "4 NaN    NaN         NaN    NaN   NaN       NaN    NaN      NaN       NaN\n",
      "\n",
      "Missing Values in Each Column:\n",
      "id               6961\n",
      "action           6961\n",
      "coordinates      6961\n",
      "button         256130\n",
      "delta            9456\n",
      "distance         7015\n",
      "speed            7015\n",
      "user_id          7033\n",
      "timestamp        6961\n",
      "dtype: int64\n",
      "\n",
      "Number of Rows with Missing Data: 256445\n",
      "Number of Complete Rows (no missing values): 2913\n",
      "\n",
      "Data Types of Each Column:\n",
      "id             float64\n",
      "action          object\n",
      "coordinates     object\n",
      "button          object\n",
      "delta           object\n",
      "distance       float64\n",
      "speed          float64\n",
      "user_id        float64\n",
      "timestamp       object\n",
      "dtype: object\n",
      "\n",
      "Basic Statistics (for numerical columns):\n",
      "                  id       distance          speed        user_id\n",
      "count  252397.000000  252343.000000  252343.000000  252325.000000\n",
      "mean   190160.999770      12.704394     629.512314      52.270322\n",
      "std     72860.882682      35.375617    1233.469142      19.709480\n",
      "min     63962.000000       0.000000       0.000000       1.000000\n",
      "25%    127062.000000       1.414214      66.666664      39.000000\n",
      "50%    190161.000000       4.000000     230.769230      58.000000\n",
      "75%    253260.000000      12.000000     677.596400      66.000000\n",
      "max    316359.000000    1511.016200   84090.730000      85.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the trimmed dataset (assuming mouse_data_trimmed was saved or is in memory)\n",
    "# If you haven't saved it yet, you can directly use mouse_data_trimmed\n",
    "mouse_data_trimmed = pd.read_csv(\"mouse_modified_trimmed.csv\")\n",
    "\n",
    "# 1. Check the shape of the dataset\n",
    "print(f\"Dataset Shape: {mouse_data_trimmed.shape}\")  # Number of rows and columns\n",
    "\n",
    "# 2. Check the first few rows to understand the data structure\n",
    "print(\"\\nFirst 5 Rows of the Dataset:\")\n",
    "print(mouse_data_trimmed.head())\n",
    "\n",
    "# 3. Check for missing values in the dataset\n",
    "missing_values = mouse_data_trimmed.isnull().sum()  # Count missing values per column\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# 4. Check if there are any rows with missing data (rows with NaN in any column)\n",
    "missing_rows = mouse_data_trimmed.isnull().any(axis=1).sum()  # Count rows with any missing data\n",
    "print(f\"\\nNumber of Rows with Missing Data: {missing_rows}\")\n",
    "\n",
    "# 5. Check for the number of complete rows (no missing values in any column)\n",
    "complete_rows = mouse_data_trimmed.notnull().all(axis=1).sum()  # Count rows with no missing data\n",
    "print(f\"Number of Complete Rows (no missing values): {complete_rows}\")\n",
    "\n",
    "# 6. Check the data types of each column to understand the structure\n",
    "print(\"\\nData Types of Each Column:\")\n",
    "print(mouse_data_trimmed.dtypes)\n",
    "\n",
    "# 7. Check basic statistics of the dataset\n",
    "print(\"\\nBasic Statistics (for numerical columns):\")\n",
    "print(mouse_data_trimmed.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d7b56b7-f582-4e7a-8895-c2f1526dcf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 259358\n",
      "Rows with Missing Data (First 6961): 6961\n",
      "Rows with Non-Missing Data (After 6961): 2913\n",
      "Total Rows with Missing Data: 256445\n",
      "Total Rows with Complete Data: 2913\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the trimmed dataset\n",
    "mouse_data_trimmed = pd.read_csv(\"mouse_modified_trimmed.csv\")\n",
    "\n",
    "# 1. Check the number of rows with missing data in the first 6,961 rows\n",
    "first_missing_rows = mouse_data_trimmed.iloc[:6961].isnull().any(axis=1).sum()\n",
    "\n",
    "# 2. Check the number of rows with no missing data in rows 6962 to the end\n",
    "non_missing_rows_after_6961 = mouse_data_trimmed.iloc[6961:].notnull().all(axis=1).sum()\n",
    "\n",
    "# 3. Check the total number of missing rows and complete rows\n",
    "missing_rows_total = first_missing_rows + (mouse_data_trimmed.isnull().any(axis=1).sum() - first_missing_rows)\n",
    "\n",
    "# 4. Check the total number of rows in the dataset\n",
    "total_rows = len(mouse_data_trimmed)\n",
    "\n",
    "# 5. Number of complete rows\n",
    "complete_rows_total = total_rows - missing_rows_total\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Rows: {total_rows}\")\n",
    "print(f\"Rows with Missing Data (First 6961): {first_missing_rows}\")\n",
    "print(f\"Rows with Non-Missing Data (After 6961): {non_missing_rows_after_6961}\")\n",
    "print(f\"Total Rows with Missing Data: {missing_rows_total}\")\n",
    "print(f\"Total Rows with Complete Data: {complete_rows_total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b47ce2c1-ec6d-4eb0-abf4-e8b89d2c522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 259358\n",
      "Rows with Missing Data (First 6961): 6961\n",
      "Rows with Non-Missing Data (After 6961): 2913\n",
      "Total Rows with Missing Data: 6961\n",
      "Total Rows with Complete Data: 2913\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the trimmed dataset\n",
    "mouse_data_trimmed = pd.read_csv(\"mouse_modified_trimmed.csv\")\n",
    "\n",
    "# 1. Check the number of rows with missing data in the first 6,961 rows\n",
    "first_missing_rows = mouse_data_trimmed.iloc[:6961].isnull().any(axis=1).sum()\n",
    "\n",
    "# 2. Check the number of rows with no missing data in rows 6962 to the end\n",
    "non_missing_rows_after_6961 = mouse_data_trimmed.iloc[6961:].notnull().all(axis=1).sum()\n",
    "\n",
    "# 3. Total rows with missing data are in the first 6961\n",
    "missing_rows_total = first_missing_rows\n",
    "\n",
    "# 4. Total complete rows are from 6962 to 259358, since they have no missing data\n",
    "complete_rows_total = non_missing_rows_after_6961\n",
    "\n",
    "# 5. Check the total number of rows in the dataset\n",
    "total_rows = len(mouse_data_trimmed)\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Rows: {total_rows}\")\n",
    "print(f\"Rows with Missing Data (First 6961): {first_missing_rows}\")\n",
    "print(f\"Rows with Non-Missing Data (After 6961): {non_missing_rows_after_6961}\")\n",
    "print(f\"Total Rows with Missing Data: {missing_rows_total}\")\n",
    "print(f\"Total Rows with Complete Data: {complete_rows_total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1924c38-7b1f-42b1-a1c2-198374f4ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 259358\n",
      "Rows with Missing Data (First 6961): 6961\n",
      "Rows with Non-Missing Data (After 6961): 2913\n",
      "Total Rows with Missing Data: 6961\n",
      "Total Rows with Complete Data: 2913\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the trimmed dataset\n",
    "mouse_data_trimmed = pd.read_csv(\"mouse_modified_trimmed.csv\")\n",
    "\n",
    "# 1. Check for missing data in the first 6961 rows\n",
    "missing_rows_first_6961 = mouse_data_trimmed.iloc[:6961].isnull().any(axis=1).sum()\n",
    "\n",
    "# 2. Check for non-missing data in rows from 6962 to the end (which should all be complete)\n",
    "non_missing_rows_after_6961 = mouse_data_trimmed.iloc[6961:].notnull().all(axis=1).sum()\n",
    "\n",
    "# 3. Check the total number of rows\n",
    "total_rows = len(mouse_data_trimmed)\n",
    "\n",
    "# 4. Number of missing rows (from first 6961 rows)\n",
    "missing_rows_total = missing_rows_first_6961\n",
    "\n",
    "# 5. Number of complete rows (from row 6962 onward)\n",
    "complete_rows_total = non_missing_rows_after_6961\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Rows: {total_rows}\")\n",
    "print(f\"Rows with Missing Data (First 6961): {missing_rows_first_6961}\")\n",
    "print(f\"Rows with Non-Missing Data (After 6961): {non_missing_rows_after_6961}\")\n",
    "print(f\"Total Rows with Missing Data: {missing_rows_total}\")\n",
    "print(f\"Total Rows with Complete Data: {complete_rows_total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea35cb6-be4d-4484-a8ca-89ec6bfd117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 259358\n",
      "Rows with Missing Data (First 6961): 6961\n",
      "Rows with Non-Missing Data (After 6961): 2913\n",
      "Total Rows with Missing Data (Entire Dataset): 256445\n",
      "Total Rows with Complete Data (Entire Dataset): 2913\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the trimmed dataset\n",
    "mouse_data_trimmed = pd.read_csv(\"mouse_modified_trimmed.csv\")\n",
    "\n",
    "# 1. Check for missing data in the first 6961 rows\n",
    "missing_rows_first_6961 = mouse_data_trimmed.iloc[:6961].isnull().any(axis=1).sum()\n",
    "\n",
    "# 2. Check for non-missing data in rows from 6962 to the end (which should all be complete)\n",
    "non_missing_rows_after_6961 = mouse_data_trimmed.iloc[6961:].notnull().all(axis=1).sum()\n",
    "\n",
    "# 3. Total rows with missing data in the entire dataset\n",
    "total_missing_rows = mouse_data_trimmed.isnull().any(axis=1).sum()\n",
    "\n",
    "# 4. Total rows with no missing data in the entire dataset\n",
    "total_complete_rows = mouse_data_trimmed.notnull().all(axis=1).sum()\n",
    "\n",
    "# 5. Total number of rows\n",
    "total_rows = len(mouse_data_trimmed)\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Rows: {total_rows}\")\n",
    "print(f\"Rows with Missing Data (First 6961): {missing_rows_first_6961}\")\n",
    "print(f\"Rows with Non-Missing Data (After 6961): {non_missing_rows_after_6961}\")\n",
    "print(f\"Total Rows with Missing Data (Entire Dataset): {total_missing_rows}\")\n",
    "print(f\"Total Rows with Complete Data (Entire Dataset): {total_complete_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f5e4088-e22f-4c09-b8c9-4685264e46d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 259358\n",
      "Rows with Completely Missing Data: 6961\n",
      "Rows with At Least 3 Non-Missing Values: 252397\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the trimmed dataset\n",
    "mouse_data_trimmed = pd.read_csv(\"mouse_modified_trimmed.csv\")\n",
    "\n",
    "# 1. Count rows with completely missing data (i.e., all columns are missing)\n",
    "missing_rows = mouse_data_trimmed.isnull().all(axis=1).sum()\n",
    "\n",
    "# 2. Count rows with at least 3 non-missing values (out of the 9 columns)\n",
    "non_missing_rows = mouse_data_trimmed.notnull().sum(axis=1).ge(3).sum()\n",
    "\n",
    "# 3. Total number of rows\n",
    "total_rows = len(mouse_data_trimmed)\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Rows: {total_rows}\")\n",
    "print(f\"Rows with Completely Missing Data: {missing_rows}\")\n",
    "print(f\"Rows with At Least 3 Non-Missing Values: {non_missing_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc52d016-8ca2-4164-8792-fda48d0c51f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Size: (259358, 9)\n",
      "New Dataset Size after Dropping Empty Rows: (252397, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the trimmed dataset (if not already loaded)\n",
    "mouse_data_trimmed = pd.read_csv(\"mouse_modified_trimmed.csv\")\n",
    "\n",
    "# Drop rows where all columns are missing (completely empty rows)\n",
    "mouse_data_trimmed_clean = mouse_data_trimmed.dropna(how='all')\n",
    "\n",
    "# Check the new size of the dataset after dropping the empty rows\n",
    "print(f\"Original Dataset Size: {mouse_data_trimmed.shape}\")\n",
    "print(f\"New Dataset Size after Dropping Empty Rows: {mouse_data_trimmed_clean.shape}\")\n",
    "\n",
    "# Optionally, save the cleaned dataset to a new CSV file\n",
    "mouse_data_trimmed_clean.to_csv(\"mouse_modified_trimmed_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "266c398a-55b7-45a3-bf0f-bf1e42b21d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Rows of the Cleaned Dataset:\n",
      "        id    action coordinates       button delta  distance  speed  user_id  \\\n",
      "0  63962.0   pressed  (144, 403)  Button.left   NaN       0.0    0.0      NaN   \n",
      "1  63963.0  released  (144, 403)  Button.left   NaN       0.0    0.0      NaN   \n",
      "2  63964.0   pressed   (27, 541)  Button.left   NaN       0.0    0.0      NaN   \n",
      "3  63965.0  released   (27, 541)  Button.left   NaN       0.0    0.0      NaN   \n",
      "4  63966.0   pressed   (32, 277)  Button.left   NaN       0.0    0.0      NaN   \n",
      "\n",
      "                       timestamp  \n",
      "0  2025-02-26 06:56:05.412578+00  \n",
      "1  2025-02-26 06:56:05.418595+00  \n",
      "2  2025-02-26 06:56:05.424294+00  \n",
      "3  2025-02-26 06:56:05.429324+00  \n",
      "4  2025-02-26 06:56:05.434928+00  \n",
      "\n",
      "Number of Rows with Complete Data (No Missing Values in Any Column): 2913\n",
      "\n",
      "Number of Rows with Data in 1, 2, 3, ..., 8 Columns:\n",
      "{1: np.int64(0), 2: np.int64(0), 3: np.int64(0), 4: np.int64(0), 5: np.int64(54), 6: np.int64(0), 7: np.int64(2198), 8: np.int64(247232)}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset after dropping empty rows\n",
    "mouse_data_trimmed_clean = pd.read_csv(\"mouse_modified_trimmed_clean.csv\")\n",
    "\n",
    "# 1. Check the first few rows to see how the data looks now\n",
    "print(\"First 5 Rows of the Cleaned Dataset:\")\n",
    "print(mouse_data_trimmed_clean.head())\n",
    "\n",
    "# 2. Count rows with complete data (all columns non-missing)\n",
    "complete_data_rows = mouse_data_trimmed_clean.notnull().all(axis=1).sum()\n",
    "\n",
    "# 3. Count rows with data in 1, 2, 3, 4, ..., 8 columns\n",
    "data_in_columns = {}\n",
    "for i in range(1, 9):  # For rows with 1 to 8 non-missing values\n",
    "    data_in_columns[i] = (mouse_data_trimmed_clean.notnull().sum(axis=1) == i).sum()\n",
    "\n",
    "# 4. Display the results\n",
    "print(\"\\nNumber of Rows with Complete Data (No Missing Values in Any Column):\", complete_data_rows)\n",
    "print(\"\\nNumber of Rows with Data in 1, 2, 3, ..., 8 Columns:\")\n",
    "print(data_in_columns)\n",
    "\n",
    "# Optionally, display the count for rows with no missing data across all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f50ee6bc-b4ae-443e-925f-8f503c37abfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.0 in /work/festusedward-n/.local/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\n",
      "Collecting scipy>=1.8.0\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 KB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aa1b43e-bacb-4187-a3a6-e7cb34b44787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Dataset Size after Imputation: (252397, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values with the mean for numerical columns and mode for categorical columns\n",
    "numerical_columns = mouse_data_trimmed_clean.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_columns = mouse_data_trimmed_clean.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute numerical columns with the mean\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "mouse_data_trimmed_clean[numerical_columns] = imputer_num.fit_transform(mouse_data_trimmed_clean[numerical_columns])\n",
    "\n",
    "# Impute categorical columns with the most frequent value (mode)\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "mouse_data_trimmed_clean[categorical_columns] = imputer_cat.fit_transform(mouse_data_trimmed_clean[categorical_columns])\n",
    "\n",
    "# Check the updated dataset size\n",
    "print(f\"Updated Dataset Size after Imputation: {mouse_data_trimmed_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f01a9650-d6f8-4325-a478-ebe627198a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_data_trimmed_clean.to_csv(\"mouse_modified_trimmed_clean_imputed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68bf910b-96cc-4b30-9081-79fcec50de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'action', 'coordinates', 'button', 'delta', 'distance', 'speed',\n",
      "       'user_id', 'timestamp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the column names of the dataset\n",
    "print(mouse_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74e805a3-5430-43a5-9220-6c8d25ec202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns identified: Index(['action', 'coordinates', 'button', 'delta', 'timestamp'], dtype='object')\n",
      "Predicted labels for training data (1: Benign, -1: Anomaly):\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset (assuming it is cleaned and imputed)\n",
    "mouse_data = pd.read_csv(\"mouse_modified_trimmed_clean_imputed.csv\")\n",
    "\n",
    "# Identify categorical columns (those with string values)\n",
    "categorical_columns = mouse_data.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical columns identified:\", categorical_columns)\n",
    "\n",
    "# Initialize LabelEncoder for encoding categorical columns\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode categorical columns (transform strings to numbers)\n",
    "for col in categorical_columns:\n",
    "    mouse_data[col] = label_encoder.fit_transform(mouse_data[col])\n",
    "\n",
    "# Now, we can proceed with the previous steps of scaling and model training\n",
    "# Drop non-relevant columns (if 'id' or 'timestamp' columns exist)\n",
    "X = mouse_data.drop(columns=['id', 'timestamp'], errors='ignore')\n",
    "\n",
    "# Feature scaling (important for SVM)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize One-Class SVM for anomaly detection\n",
    "model = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=\"auto\")  # nu is the fraction of outliers\n",
    "\n",
    "# Train the One-Class SVM model on benign data\n",
    "model.fit(X_scaled)\n",
    "\n",
    "# Predict anomalies (outliers). 1 means normal (Benign), -1 means anomaly (potential attacker)\n",
    "y_pred = model.predict(X_scaled)\n",
    "\n",
    "# Convert the predictions: 1 for normal (Benign), -1 for anomaly (potential attack)\n",
    "y_pred = [1 if label == -1 else 0 for label in y_pred]\n",
    "\n",
    "# Display some predictions (just the first 10 predictions here)\n",
    "print(\"Predicted labels for training data (1: Benign, -1: Anomaly):\")\n",
    "print(y_pred[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253e3fe-da58-437a-b021-89015768e6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
